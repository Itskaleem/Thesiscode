{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","import gc\n","import numpy as np\n","\n","\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","\n","SEED = 1234\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3919,"status":"ok","timestamp":1710342268442,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"J-1bIDKgUF2a"},"outputs":[],"source":["Configuration = {'RootPath': r\"C:\\Users\\Utente\\Projects\\Thesis\",\n","                 'PositiveSamples':r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\Recaptured1\",\n","                 'NegativeSamples':r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\Original1\",\n","                 'DLC_dataset': r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\",\n","                 'Methods': ['ResNet50','EfficientNet','MobileNet'],\n","                 'Batchsize':32,\n","                 'train_size': 0.80,\n","                 'val_size' : 0.10,\n","                 'test_size' : 0.10,\n","                 'n_workers':1,\n","                 'epochs':30,\n","                 'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710342639061,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"nrMh9cxxUF2g"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","from torchvision.transforms import ToTensor\n","import cv2\n","import torchvision\n","import pandas as pd\n","from sklearn.metrics import precision_recall_curve\n","from sklearn import metrics\n","import random\n","\n","class DocumentRecaptureDataset(Dataset):\n","    def __init__(self,samples,labels,transforms = ToTensor(),oversample=False):\n","        self.samples = samples\n","        self.labels = labels\n","        self.oversample = oversample\n","        self.transform = transforms\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        sample = dict()\n","        image = cv2.imread(self.samples[idx])  # Open image using PIL\n","\n","        if self.oversample:\n","            random_int = random.randint(0, 4)\n","            match random_int:\n","                case 0:\n","                    #horizontal flip \n","                    image = cv2.flip(image, 1)\n","                case 1:\n","                    #vertical flip\n","                    image = cv2.flip(image, 0)\n","                case 2: \n","                    image = cv2.rotate(image,cv2.ROTATE_90_CLOCKWISE)\n","                case 3:\n","                    image = cv2.rotate(image,cv2.ROTATE_90_COUNTERCLOCKWISE)\n","            \n","\n","        label = torch.tensor(self.labels[idx], dtype=torch.int64)\n","\n","\n","        if self.transform:\n","            \n","            image = self.transform(image)\n","\n","        sample['image'] = image\n","        sample['label'] = label  \n","\n","        return sample\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# UTILS:\n"," In this section I will define some utility functions that will help me later to perform operations on deep learning pipeline."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","def load_paths(path,group,test_doc):\n","\n","    \"\"\"\n","    Load file paths for training and testing datasets based on the given directory structure.\n","\n","    This function walks through the directory specified by `path` and identifies image files (i.e., files\n","    ending with .jpg or .png). Depending on the file's full path, it categorizes the images into training\n","    or testing samples.\n","\n","    If `test_doc` is part of the file path, the file is added to the `test_samples` list. Otherwise, it is \n","    added to `train_samples`. For the \"negative\" group and files that contain \"KaleemCam\" in their path, \n","    the function limits the number of added files to 200.\n","\n","    Parameters:\n","    ----------\n","    path : str\n","        The root directory to walk through and load image file paths.\n","    group : str\n","        A string identifier (such as 'negative') to determine the break condition when processing \n","        specific files (e.g., \"KaleemCam\").\n","    test_doc : str\n","        A substring to identify test documents. If this substring is found in the file path, \n","        the file is added to the test samples list.\n","\n","    Returns:\n","    -------\n","    train_samples : list of str\n","        A list of file paths corresponding to the training samples.\n","    test_samples : list of str\n","        A list of file paths corresponding to the testing samples.\n","    \"\"\"\n","\n","\n","    train_samples = []\n","    test_samples = []\n","    \n","    for root, _, files in os.walk(path):\n","\n","        count = 0\n","        for file in files:\n","            if file.endswith((\".jpg\", \".png\")):  \n","                full_path = os.path.join(root, file)  \n","\n","                if test_doc in full_path:\n","                    test_samples.append(full_path)\n","                else:\n","                    train_samples.append(full_path)\n","              \n","              \n","                if count >= 200 and 'negative' in group and 'KaleemCam' in full_path:\n","                    break\n","                else:\n","                    count += 1\n","             \n","    return train_samples, test_samples\n","\n","\n","def log_distrinution(No_Positive_Samples,No_Negative_samples):\n","\n","    labels = ['Recaptured_samples', 'Original_samples']\n","\n","    plt.bar(labels,[No_Positive_Samples,No_Negative_samples], color=['blue', 'green'])\n","    plt.savefig('temp.png')\n","\n","    temp = cv2.imread('temp.png')\n","\n","    return temp\n","\n","\n","def log_samples(train_loader):\n","    \"\"\"\n","    Log and visualize a sample of positive and negative images from the dataset.\n","\n","    This function iterates through the dataset provided by `train_loader` and selects\n","    five positive and five negative images. It categorizes the images based on their \n","    labels: '0' for negative and any other label for positive. Once the function has \n","    collected 5 samples for each category, it breaks the loop to optimize processing time.\n","\n","    The collected images are then combined into grids for easy visualization using \n","    `torchvision.utils.make_grid()`.\n","\n","    Parameters:\n","    ----------\n","    train_loader : DataLoader\n","        A PyTorch DataLoader containing the dataset from which images and labels are sampled.\n","        Each element in the dataset is expected to be a dictionary with 'image' and 'label' keys.\n","\n","    Returns:\n","    -------\n","    positive_images : Tensor\n","        A grid of 5 positive images, ready for visualization.\n","    negative_images : Tensor\n","        A grid of 5 negative images, ready for visualization.\n","\n","    Notes:\n","    ------\n","    - The dataset is expected to be structured such that each item is a dictionary containing\n","      'image' and 'label' keys.\n","    - Label '0' represents negative samples, while all other labels are treated as positive samples.\n","    - If fewer than 5 positive or negative images are available, the function will return\n","      whatever images it has collected by the time the loop ends.\n","    \"\"\"\n","    \n","    positive_images = []\n","    negative_images = []\n","    \n","    # Define the required number of samples for each category\n","    max_samples = 5\n","\n","    # Loop through the dataset, assuming each item has 'image' and 'label' keys\n","    for i in range(len(train_loader.dataset)):\n","        sample = train_loader.dataset[i]\n","        label = sample['label']\n","        image = sample['image']\n","\n","        # Add to negative or positive samples\n","        if label == 0 and len(negative_images) < max_samples:\n","            negative_images.append(image)\n","        elif label != 0 and len(positive_images) < max_samples:\n","            positive_images.append(image)\n","\n","        # Break if we have enough images for both categories\n","        if len(negative_images) == max_samples and len(positive_images) == max_samples:\n","            break\n","\n","    # Ensure we have enough images to create grids\n","    if len(negative_images) < max_samples:\n","        print(f\"Warning: Only {len(negative_images)} negative samples found.\")\n","    if len(positive_images) < max_samples:\n","        print(f\"Warning: Only {len(positive_images)} positive samples found.\")\n","    \n","    # Create image grids using torchvision\n","    positive_grid = torchvision.utils.make_grid(positive_images)\n","    negative_grid = torchvision.utils.make_grid(negative_images)\n","\n","    return positive_grid, negative_grid\n","\n","\n","\n","def calculate_metrics(y_true, functional_margin, thresholds, tag=None, model_type=None, writer=None):\n","    \"\"\"\n","    Calculate evaluation metrics and optionally log results to a CSV or TensorBoard writer.\n","\n","    This function computes binary classification metrics such as accuracy, precision, recall, and F1 score,\n","    based on the predicted values from a thresholded functional margin. The function can also log the results\n","    to a CSV file or write them to a TensorBoard writer.\n","\n","    Parameters:\n","    ----------\n","    y_true : list or array\n","        Ground truth (true binary labels).\n","    functional_margin : list or array\n","        Predicted margins (continuous values), which will be thresholded to generate binary predictions.\n","    thresholds : float\n","        The threshold value to convert the continuous functional margins into binary predictions (0 or 1).\n","    tag : str, optional\n","        A tag for naming result files and scalar logs (e.g., 'experiment1').\n","    model_type : str, optional\n","        A string representing the model type, used for naming result files.\n","    writer : torch.utils.tensorboard.SummaryWriter, optional\n","        A TensorBoard writer for logging metrics.\n","\n","    Returns:\n","    -------\n","    accuracy : float\n","        Accuracy of the predictions.\n","    precision : float\n","        Precision of the predictions.\n","    recall : float\n","        Recall of the predictions.\n","    f1 : float\n","        F1 score (macro-averaged) of the predictions.\n","\n","    Notes:\n","    ------\n","    - If `tag` or `model_type` are provided, results will be saved in a CSV file.\n","    - If `writer` is provided, metrics will be logged to TensorBoard with scalar values.\n","    \"\"\"\n","\n","    # Convert functional_margin to binary predictions using vectorized operations\n","    y_pred = np.where(np.array(functional_margin) < thresholds, 0, 1)\n","\n","    # Calculate classification metrics\n","    accuracy = metrics.accuracy_score(y_true, y_pred)\n","    precision = metrics.precision_score(y_true, y_pred, zero_division=0)\n","    recall = metrics.recall_score(y_true, y_pred, zero_division=0)\n","    f1 = metrics.f1_score(y_true, y_pred, average='macro', zero_division=0)\n","\n","    # Save results to CSV if tag and model_type are provided\n","    if tag or model_type:\n","        csv_filename = f\"results_{tag}_{model_type}.csv\" if tag else f\"results_{model_type}.csv\"\n","        pd.DataFrame({'gt': y_true, 'pred': y_pred}).to_csv(csv_filename, index=False)\n","    \n","    # Log metrics to TensorBoard if a writer is provided\n","    if writer:\n","        writer.add_scalar(f'{tag}/Test Accuracy' if tag else 'Test Accuracy', accuracy, 0)\n","        writer.add_scalar(f'{tag}/Test Precision' if tag else 'Test Precision', precision, 0)\n","        writer.add_scalar(f'{tag}/Test Recall' if tag else 'Test Recall', recall, 0)\n","        writer.add_scalar(f'{tag}/Test F1 score' if tag else 'Test F1 score', f1, 0)\n","\n","    return accuracy, precision, recall, f1\n","\n","def find_threshold(y_true, functional_margin):\n","    \"\"\"\n","    Find the best threshold that maximizes the F1 score based on precision-recall curve.\n","\n","    This function computes the precision-recall curve for a binary classification task,\n","    and calculates the F1 scores for each threshold. It returns the threshold that \n","    corresponds to the highest F1 score.\n","\n","    Parameters:\n","    ----------\n","    y_true : list or array\n","        Ground truth binary labels (0 or 1).\n","    functional_margin : list or array\n","        Predicted scores or functional margins (continuous values).\n","\n","    Returns:\n","    -------\n","    best_threshold : float\n","        The threshold value that results in the highest F1 score.\n","    best_f1_score : float\n","        The highest F1 score achieved with the best threshold.\n","\n","    Notes:\n","    ------\n","    - F1 score is the harmonic mean of precision and recall, and is used to balance \n","      the trade-off between the two metrics.\n","    - The function assumes that `y_true` contains only binary labels (0 or 1).\n","    \"\"\"\n","    \n","    # Calculate precision-recall curve\n","    precision, recall, thresholds = precision_recall_curve(y_true, functional_margin)\n","\n","    # Avoid division by zero by handling edge cases\n","    f1_scores = np.divide(2 * recall * precision, recall + precision, out=np.zeros_like(precision), where=(recall + precision) != 0)\n","\n","    # Find the index of the best F1 score\n","    best_index = np.argmax(f1_scores)\n","    best_threshold = thresholds[best_index] if len(thresholds) > 0 else None\n","    best_f1_score = f1_scores[best_index]\n","\n","    # Return the best threshold and F1 score\n","    return best_threshold, best_f1_score\n","    \n","\n","def dlc_dataset(path):\n","    positive_train_samples = []\n","    negative_train_samples = []\n","    positive_test_samples = []\n","    negative_test_samples = []\n","    \n","    for root, _, files in os.walk(path):\n","        count = 0\n","        for file in sorted(files):\n","            if file.endswith((\".jpg\", \".png\")):  # Use tuple for multiple extensions\n","                full_path = os.path.join(root, file)  # Use a different variable name here\n","\n","                if 'or' in full_path:\n","                    count += 1\n","                    if 'esp_id' in full_path:\n","                        negative_test_samples.append(full_path)\n","                    else:\n","                        negative_train_samples.append(full_path)\n","                        \n","                else:\n","                    \n","                    if 'esp_id' in full_path:\n","                        positive_test_samples.append(full_path)\n","                    else:\n","                        positive_train_samples.append(full_path)\n","\n","            if count >= 10:\n","                break\n","            \n","            \n","    print(len(positive_test_samples),len(negative_test_samples),len(positive_train_samples),len(negative_train_samples))\n","    \n","    train_samples = positive_train_samples + negative_train_samples\n","    train_labels = [1] * len(positive_train_samples) + [0] * len(negative_train_samples)\n","\n","    test_samples = positive_test_samples + negative_test_samples\n","    test_labels = [1] * len(positive_test_samples) + [0] * len(negative_test_samples)\n","    return train_samples , train_labels, test_samples, test_labels\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Model Definintion:\n","\n","In this section we define a very comprehensive function that return us model and corresponding transoformations. It will recieve several parametes of choice such as pretraining signifying if the pretrained model is required and many more that self explanatory. "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710342639061,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"4METQ35yUF2g"},"outputs":[],"source":["import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","import torchvision.transforms as T\n","from torchvision.transforms import v2\n","\n","def build_model_and_transforms(pretrained=True, fine_tune=True, num_classes=1, initialize=True,model_type='Resnet34'):\n","    if pretrained:\n","        match model_type:\n","            case 'Resnet18':\n","                print(\"[INFO]: Loading pre-trained weights for : {}\".format(model_type))\n","                model = models.resnet18(weights='DEFAULT',progress=True)\n","                model.fc = nn.Linear(model.fc.in_features, num_classes)\n","            case 'Resnet34':\n","                print(\"[INFO]: Loading pre-trained weights for : {}\".format(model_type))\n","                model = models.resnet34(weights='DEFAULT',progress=True)\n","                model.fc = nn.Linear(model.fc.in_features, num_classes)\n","            case 'Resnet50':\n","                print(\"[INFO]: Loading pre-trained weights for : {}\".format(model_type))\n","                model = models.resnet50(weights='DEFAULT',progress=True)\n","                model.fc = nn.Linear(model.fc.in_features, num_classes)\n","            case 'EfficientnetM':\n","                model = models.efficientnet_v2_m(weights='DEFAULT',progress = True)\n","                model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes)\n","            case 'EfficientnetS':\n","                model = models.efficientnet_v2_s(weights='DEFAULT',progress=True)      \n","                model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes)\n","            case 'Efficientnetb0':\n","                model = models.efficientnet_b0(weights='DEFAULT',progress=True)\n","                for param in model.parameters():\n","                    param.requires_grad = False\n","                model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes)\n","            \n","                \n","    else:\n","        match model_type:\n","            case 'Resnet18':\n","                print(\"[INFO]: Loading pre-trained weights for : {}\".format(model_type))\n","                model = models.resnet18(pretrained=False,progress=True)\n","                model.fc = nn.Linear(model.fc.in_features, num_classes)\n","            case 'Resnet34':\n","                print(\"[INFO]: Loading pre-trained weights for : {}\".format(model_type))\n","                model = models.resnet34(pretrained=False,progress=True)\n","                for param in model.parameters():\n","                    param.requires_grad = False\n","                model.fc = nn.Linear(model.fc.in_features, num_classes)\n","            case 'Resnet50':\n","                print(\"[INFO]: Loading pre-trained weights for : {}\".format(model_type))\n","                model = models.resnet50(pretrained=False,progress=True)\n","                model.fc = nn.Linear(model.fc.in_features, num_classes)\n","            case 'EfficientnetM':\n","                model = models.efficientnet_v2_m(pretrained=False,progress = True)\n","                model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes)\n","            case 'Efficientnetb0':\n","                model = models.efficientnet_b0(pretrained=False,progress=True)\n","                model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes)\n","            case 'EfficientnetS':\n","                model = models.efficientnet_v2_s(pretrained=False,progress=True)\n","                model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes)\n","        \n","\n","    if fine_tune:\n","        print(\"[INFO]: Fine-tuning all layers...\")\n","        for param in list(model.children())[-1:]:\n","            for p in param.parameters():\n","                p.requires_grad = True\n","\n","    else:\n","        print(\"[INFO]: Freezing hidden layers...\")\n","        for param in model.parameters():  \n","            param.requires_grad = False\n","\n","    if initialize and pretrained == False:\n","        print(\"[INFO]: Initializing parameters...\")\n","        for param in model.parameters():\n","            if len(param.shape) > 1:  # Exclude biases\n","                nn.init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n","\n","\n","    if 'Resnet' in model_type:\n","        train_transforms =T.Compose([\n","            T.ToPILImage(),\n","            T.CenterCrop((224,224)),\n","            T.Pad(padding=12, fill=0, padding_mode='constant'),\n","            T.ToTensor(),\n","            ])\n","\n","        test_transforms = T.Compose([\n","            T.ToPILImage(),\n","            T.CenterCrop((224,224)),\n","            T.Pad(padding=12, fill=0, padding_mode='constant'),\n","            T.ToTensor(),\n","            ])\n","    elif 'Efficient' in model_type or 'Inception' in model_type:\n","        train_transforms =T.Compose([\n","            T.ToPILImage(),\n","            T.CenterCrop((224,224)),\n","            \n","            T.ToTensor()\n","            ])\n","\n","        test_transforms = T.Compose([\n","            T.ToPILImage(),\n","            T.CenterCrop((224,224)),\n","            T.ToTensor(),\n","            ])\n","\n","\n","    return model.to(Configuration['device']),model_type,train_transforms,test_transforms\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def get_model(checkpoint_path):\n","\n","    \"\"\"this function I had defined in order to load already trained model that later needs to be finetuned on different resolution dataset.\"\"\"\n","    \n","    model = models.efficientnet_v2_s(weights='DEFAULT', progress=True)\n","    model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=1)\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    for param in list(model.parameters())[:-8]:\n","        param.requires_grad = False\n","\n","    return model"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710342643836,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"ePrZgtSnUF2h"},"outputs":[],"source":["import torch.utils\n","from torch.utils.data import DataLoader\n","import os\n","import torch.utils.data\n","\n","\n","def get_data(batch_size, positive_samples_path, negative_samples_path, train_transforms, test_transforms,test_doc,writer=None):\n"," \n","    train_samples = []\n","    test_samples = []\n","    train_labels = []\n","    test_labels = []\n","\n","    train_positive, test_positive = load_paths(positive_samples_path,'positive',test_doc)\n","    train_samples.extend(train_positive)\n","    train_labels.extend([1] * len(train_positive))  # Fix label count issue here\n","    test_samples.extend(test_positive)\n","    test_labels.extend([1] * len(test_positive))\n","\n","    train_samples_transformed = []\n","    test_samples_transformed = []\n","    train_labels_transformed = []\n","    test_labels_transformed = []\n","\n","    '''\n","    #this was used in case I need to upsample the minority class which in our case was recaptured samples\n","\n","    train_positive_transformed, test_positive_transformed = load_paths(positive_samples_path,'positive',test_doc)\n","    \n","    train_samples_transformed.extend(train_positive_transformed)\n","    train_labels_transformed.extend([1]* len(train_positive_transformed))\n","    test_samples_transformed.extend(test_positive_transformed)\n","    test_labels_transformed.extend([1] * len(test_positive_transformed))\n","    '''\n","\n","    train_negative, test_negative = load_paths(negative_samples_path,'negative',test_doc)\n","    train_samples.extend(train_negative)\n","    train_labels.extend([0] * len(train_negative))  # And here\n","    test_samples.extend(test_negative)\n","    test_labels.extend([0] * len(test_negative))\n","\n","\n","    if writer:\n","        writer.add_text('No# distrubtion in training Images',str({'positive': len(train_positive),'negative':len(train_negative)}),0)\n","        writer.add_text('No# distrubtion in testing Images',str({'positive': len(test_positive),'negative':len(test_negative)}),0)\n","\n","   \n","    # Creating datasets\n","    train_transformations = DocumentRecaptureDataset(train_samples_transformed,labels = train_labels_transformed,oversample=True,transforms=train_transforms)\n","    train_data = DocumentRecaptureDataset(train_samples, labels=train_labels, transforms=train_transforms,oversample=False)\n","    train_data = torch.utils.data.ConcatDataset([train_transformations,train_data])\n","    val_data = DocumentRecaptureDataset(test_samples, labels=test_labels, transforms=test_transforms,oversample=False)\n","    val_transformations = DocumentRecaptureDataset(test_samples_transformed,labels= test_labels_transformed,oversample=True,transforms=test_transforms)\n","    val_data = torch.utils.data.ConcatDataset([val_transformations,val_data])\n","\n","    test_data = val_data\n","\n","    # DataLoaders\n","    train_loader = DataLoader(train_data, batch_size=batch_size,shuffle=True)\n","    val_loader = DataLoader(val_data, batch_size=batch_size)\n","    test_loader = DataLoader(test_data, batch_size=batch_size)\n","\n","    return train_loader,val_loader,test_loader\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import torch.utils\n","from torch.utils.data import DataLoader\n","import os\n","import torch.utils.data\n","\n","\n","def get_data_dlc(batch_size, positive_samples_path, negative_samples_path, train_transforms, test_transforms,dlc_path,writer=None):\n"," \n","\n","    train_samples_dlc ,train_labels_dlc,test_samples_dlc,test_labels_dlc = dlc_dataset(dlc_path)\n","\n","    train_samples = []\n","    test_samples = []\n","    train_labels = []\n","    test_labels = []\n","\n","    train_positive, test_positive = load_paths(positive_samples_path,'positive')\n","    train_samples.extend(train_positive)\n","    train_labels.extend([1] * len(train_positive))  # Fix label count issue here\n","    test_samples.extend(test_positive)\n","    test_labels.extend([1] * len(test_positive))\n"," \n"," \n","    train_negative, test_negative = load_paths(negative_samples_path,'negative')\n","    train_samples.extend(train_negative)\n","    train_labels.extend([0] * len(train_negative))  # And here\n","    test_samples.extend(test_negative)\n","    test_labels.extend([0] * len(test_negative))\n","\n","    \n","    if writer:\n","        writer.add_text('No# distrubtion in training Images',str({'positive': len(train_positive),'negative':len(train_negative)}),0)\n","        writer.add_text('No# distrubtion in testing Images',str({'positive': len(test_positive),'negative':len(test_negative)}),0)\n","\n","   \n","    # Creating datasets\n","    train_data = DocumentRecaptureDataset(train_samples_dlc, labels=train_labels_dlc, transforms=train_transforms,oversample=False)\n","    val_data = DocumentRecaptureDataset(test_samples_dlc, labels=test_labels_dlc, transforms=test_transforms,oversample=False)\n","    test_data = DocumentRecaptureDataset(test_samples,test_labels,transforms=test_transforms,oversample=False)\n","\n","\n","    # DataLoaders\n","    train_loader = DataLoader(train_data, batch_size=batch_size,shuffle=True)\n","    val_loader = DataLoader(val_data, batch_size=batch_size)\n","    test_loader = DataLoader(test_data, batch_size=batch_size)\n","\n","    return train_loader,val_loader,test_loader\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n","Below we define our training logic. Depending on the requirements it trains and save the chosen model"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710342659598,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"ESpRWEPnUF2k"},"outputs":[],"source":["\n","import time\n","from tqdm import tqdm\n","\n","\n","def find_correct_pred(gt,pred):\n","    count = 0\n","    for i,j in zip(gt,pred):\n","        if i == j:\n","            count += 1\n","\n","    return count\n","\n","def test(net, test_loader, device='cpu'):\n","    net.eval()\n","\n","    original = []\n","    outputs_pr = []\n","\n","    with torch.no_grad():\n","        for index, batch in enumerate(tqdm(test_loader)):\n","            images = batch['image'].to(device)\n","            outputs = net(images)\n","            outputs_pr.extend(outputs.cpu().numpy()) \n","\n","            original.extend(list(batch['label'].type(torch.int32).numpy()))\n","\n","    return {'gt': original,'raw_outputs':outputs_pr}\n","\n","\n","def train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=20, device='cpu', checkpoint_epochs=5,writer = None,model_type=None):\n","    start = time.time()\n","    print(f'Training for {epochs} epochs on {device}')\n","\n"," \n","    for epoch in range(1,epochs+1):\n","        print(f\"Epoch {epoch}/{epochs}\")\n","\n","        net.train()  \n","        train_loss = torch.tensor(0.)  \n","        train_accuracy = torch.tensor(0.)\n","        for index,batch in enumerate(tqdm(train_dataloader)):\n","\n","            images = batch['image'].to(device)\n","            labels = batch['label']#.to(device)\n","            labels = labels.unsqueeze(1).float()\n","\n","            preds = net(images).cpu()\n","\n","            loss = criterion(preds, labels)\n","\n","            optimizer.zero_grad()\n","\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            with torch.no_grad():\n","                predicted_labels = list((preds > 0.5).type(torch.int32).numpy())\n","                predicted =[item[0] for item in predicted_labels]\n","                gt = list(batch['label'].type(torch.int32).numpy())\n","\n","                train_loss += loss * train_dataloader.batch_size\n","                train_accuracy += find_correct_pred(gt,predicted)\n","                \n","\n","        \n","        if valid_dataloader is not None:\n","            net.eval()  \n","            valid_loss = torch.tensor(0.)\n","            valid_accuracy = torch.tensor(0.)\n","            with torch.no_grad():\n","                for index, batch in enumerate(tqdm(valid_dataloader)):\n","                    \n","\n","                    images = batch['image'].to(device)\n","                    labels = batch['label']\n","                    labels = labels.unsqueeze(1).float()\n","\n","                    preds = net(images).cpu()\n","\n","                    predicted_labels = list((preds > 0.5).type(torch.int32).numpy())\n","\n","                    predicted =[item[0] for item in predicted_labels]\n","                    \n","                    gt = list(batch['label'].type(torch.int32).numpy())\n","                    valid_loss += loss * valid_dataloader.batch_size\n","                    valid_accuracy +=  find_correct_pred(gt,predicted)\n","\n","                  \n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        # Print out what's happening\n","        print(\n","          f\"Epoch: {epoch} | \"\n","          f\"train_loss: {train_loss/len(train_dataloader.dataset):.4f} | \"\n","          f\"train_accuracy: {100*train_accuracy/len(train_dataloader.dataset):.4f} | \"\n","          f\"valid_loss: {valid_loss/len(valid_dataloader.dataset):.4f} | \"\n","          f\"valid_accuracy: {100*valid_accuracy/len(valid_dataloader.dataset):.4f}\"\n","        )\n","\n","\n","        if writer:\n","            ### New: Experiment tracking ###\n","            # Add loss results to SummaryWriter\n","            writer.add_scalar(tag=\"Train_loss\", scalar_value = train_loss/len(train_dataloader.dataset),global_step = epoch)\n","            writer.add_scalar(tag=\"Valid_loss\", scalar_value = valid_loss/len(valid_dataloader.dataset),global_step = epoch)\n","            writer.add_scalar(tag=\"Train_accuracy\", scalar_value = 100*train_accuracy/len(train_dataloader.dataset),global_step = epoch)\n","            writer.add_scalar(tag=\"Test_accuracy\", scalar_value = 100*valid_accuracy/len(valid_dataloader.dataset),global_step = epoch)\n","            \n","    \n","        if epoch%10==0:\n","            torch.save({\n","                'epoch': epoch,\n","                'state_dict': net.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","            }, f'./kfold/{model_type}_{epoch}.pth.tar')\n","\n","    end = time.time()\n","    print(f'Total training time: {end-start:.1f} seconds')\n","    return net"]},{"cell_type":"markdown","metadata":{},"source":["# Loss\n","During my thesis I had difficulty finding the right library for using the focalloss so I had copied the following code from git hub."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","\n","class FOCALLOSS(nn.Module):\n","    def __init__(self, alpha= 0.25, gamma= 2,reduction = None) -> None:\n","        super(FOCALLOSS,self).__init__()\n","        \n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduction=reduction\n","\n","    def forward(self,inputs,targets):\n","        \"\"\"\n","        Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py .\n","        Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n","        Args:\n","            inputs: A float tensor of arbitrary shape.\n","                    The predictions for each example.\n","            targets: A float tensor with the same shape as inputs. Stores the binary\n","                    classification label for each element in inputs\n","                    (0 for the negative class and 1 for the positive class).\n","            alpha: (optional) Weighting factor in range (0,1) to balance\n","                    positive vs negative examples or -1 for ignore. Default = 0.25\n","            gamma: Exponent of the modulating factor (1 - p_t) to\n","                balance easy vs hard examples.\n","            reduction: 'none' | 'mean' | 'sum'\n","                    'none': No reduction will be applied to the output.\n","                    'mean': The output will be averaged.\n","                    'sum': The output will be summed.\n","        Returns:\n","            Loss tensor with the reduction option applied.\n","        \"\"\"\n","        p = torch.sigmoid(inputs)\n","        ce_loss = F.binary_cross_entropy_with_logits(\n","            inputs, targets, reduction=\"none\"\n","        )\n","        p_t = p * targets + (1 - p) * (1 - targets)\n","        loss = ce_loss * ((1 - p_t) ** self.gamma)\n","\n","        if self.alpha >= 0:\n","            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n","            loss = alpha_t * loss\n","\n","        if self.reduction == \"mean\":\n","            loss = loss.mean()\n","        elif self. reduction == \"sum\":\n","            loss = loss.sum()\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1494,"status":"ok","timestamp":1710342645325,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"3h3HtScbUF2i","outputId":"7f63e754-a9d5-4237-8e7a-cc6eb33f602e"},"outputs":[],"source":["model,model_type,train_transforms,test_transforms = build_model_and_transforms(pretrained=True, fine_tune=True, num_classes=1,model_type='EfficientnetS',initialize=False)"]},{"cell_type":"markdown","metadata":{},"source":["#"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1783,"status":"ok","timestamp":1710342647106,"user":{"displayName":"Kaleem Ullah Kaleem Ullah","userId":"14902936011872439336"},"user_tz":-60},"id":"2O-N1UZgUF2j"},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","\n","\n","for test_doc in ['French']:\n","    writer = SummaryWriter(f'kfold_runs/efficient_focalloss_downsampled_{test_doc}')\n","    \n","    train_loader, val_loader, test_loader= get_data(Configuration['Batchsize'],Configuration['PositiveSamples'],Configuration['NegativeSamples'],train_transforms,test_transforms,test_doc,writer=writer)\n","    device = Configuration['device']\n","\n","    \n","    print(len(train_loader.dataset))\n","    print(len(test_loader.dataset))\n","    lr, weight_decay = 5e-2, 5e-5\n","    model = model.to(device)\n","\n","   \n","    criterion = FOCALLOSS(alpha=0.25,gamma=2,reduction='sum') #\n","    #criterion = BCEWithLogitsLoss(pos_weight=torch.tensor(2.),reduction='sum')\n","\n","    \n","    params_1x = [param for name, param in model.named_parameters()]\n","\n","\n","    \n","    optimizer = torch.optim.Adam([{'params':params_1x}])\n","\n","\n","    #writer.add_image('Positive images', positive_images, 0)\n","    #writer.add_image('Negative images', negative_images, 0)\n","\n","    net = train(model, train_loader, val_loader, criterion,optimizer , scheduler=None, epochs=10, device=device,writer=writer,model_type=f'efficient_focalloss_downsampled_{test_doc}')\n","    results = test(net, test_loader, device)\n","\n","    Accuracy ,Precision,Recall,F1_score = calculate_metrics(results['gt'],results['raw_outputs'],0.5,tag='our',model_type=model_type,writer=writer)\n","\n","    print(f'Accuracy: {Accuracy}\\nPrecision: {Precision}\\nRecall{Recall}\\nF1 Score: {F1_score}')\n","\n","\n","\n","    #below code is for testing on choice of document from dlc dataset.\n","\n","    positive_files = []\n","    negative_files = []\n","\n","    for folder in os.listdir(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\\esp_id\"):\n","        for file in os.listdir(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\\esp_id\",folder)):\n","            if 'or' in folder:\n","                negative_files.append(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\\esp_id\",folder,file))\n","            else:\n","                positive_files.append(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\\esp_id\",folder,file))\n","\n","\n","    all_files = positive_files + negative_files\n","\n","    labels = [1] * len(positive_files) + [0] * len(negative_files)\n","\n","    dlc_dataset = DocumentRecaptureDataset(all_files,labels,transforms=test_transforms)\n","\n","    dlc_dataloader = DataLoader(dlc_dataset, batch_size=32, shuffle=False)\n","\n","    results = test(net,dlc_dataloader,device=device)\n","\n","    Accuracy ,Precision,Recall,F1_score = calculate_metrics(results['gt'],results['raw_outputs'],threshold=0.5,tag='DLC',model_type=model_type,writer=writer)\n","\n","    print(f'Accuracy: {Accuracy}\\nPrecision: {Precision}\\nRecall{Recall}\\nF1 Score: {F1_score}')\n","\n","    \n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["7913\n","8153\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 503/503 [15:19<00:00,  1.83s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7135565791111664\n","Precision: 0.7754117451339212\n","Recall0.5890307089599394\n","F1 Score: 0.7083727398647642\n"]}],"source":["\n","device = Configuration['device']\n","\n","net = get_model(r'C:\\Users\\Utente\\Projects\\Thesis\\Evaluations\\Deep Learning Based\\kfold\\efficient_focalloss_downsampled_ahan_crop150_30.pth.tar')\n","net.to(device)\n","positive_files = []\n","negative_files = []\n","\n","for L in ['esp_id','iva_passport','alb_id','est_id','aze_passport']:\n","    for folder in sorted(os.listdir(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\"+f'\\{L}')):\n","        \n","        for file in sorted(os.listdir(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\",L,folder))):\n","            if 'or' in folder:\n","                negative_files.append(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\",L,folder,file))\n","            else:\n","                positive_files.append(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\DLC\\clips\\clips\\images\",L,folder,file))\n","\n","\n","all_files = positive_files + negative_files\n","\n","print(len(positive_files))\n","print(len(negative_files))\n","labels = [1] * len(positive_files) + [0] * len(negative_files)\n","\n","dlc_dataset = DocumentRecaptureDataset(all_files,labels,transforms=test_transforms)\n","\n","dlc_dataloader = DataLoader(dlc_dataset, batch_size=32, shuffle=False)\n","\n","results = test(net,dlc_dataloader,device=device)\n","\n","Accuracy ,Precision,Recall,F1_score = calculate_metrics(results['gt'],results['raw_outputs'],0.5,tag='DLC',model_type=model_type,writer=None)\n","\n","print(f'Accuracy: {Accuracy}\\nPrecision: {Precision}\\nRecall{Recall}\\nF1 Score: {F1_score}')\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 54/54 [00:38<00:00,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.3346938775510204\n","Precision: 0.5470588235294118\n","Recall0.08038029386343994\n","F1 Score: 0.29880376868585123\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import glob \n","\n","positive_files = []\n","negative_files = []\n","\n","\n","jpg_files = glob.glob(os.path.join(r\"C:\\Users\\Utente\\Projects\\Thesis\\doc_exp\\personal_dataset\", '**', '*.jpg'), recursive=True)\n","    \n","    \n","# Iterate through the list of jpg files\n","for jpg_file in jpg_files:\n","    # Check if the substring is in the full path\n","    if 'Or' in jpg_file:\n","        negative_files.append(jpg_file)\n","    \n","    else:\n","        positive_files.append(jpg_file)\n","\n","\n","\n","all_files = positive_files + negative_files\n","\n","\n","labels = [1] * len(positive_files) + [0] * len(negative_files)\n","\n","dlc_dataset = DocumentRecaptureDataset(all_files,labels,transforms=test_transforms)\n","\n","dlc_dataloader = DataLoader(dlc_dataset, batch_size=32, shuffle=False)\n","\n","results = test(net,dlc_dataloader,device=device)\n","\n","Accuracy ,Precision,Recall,F1_score = calculate_metrics(results['gt'],results['raw_outputs'],0.5,tag='DLC_webcam',model_type=model_type,writer=None)\n","\n","print(f'Accuracy: {Accuracy}\\nPrecision: {Precision}\\nRecall{Recall}\\nF1 Score: {F1_score}')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
